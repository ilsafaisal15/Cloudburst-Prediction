# -*- coding: utf-8 -*-
"""ML Assignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gG8dQ7PAvxUzgBmjpu5nHCh1GpnjZRNq

**1.Data Handling (NumPy & Pandas)**
"""

import pandas as pd
import numpy as np

#Load dataset into a Pandas DataFrame.

df=pd.read_csv('/content/CLOUDPAK25_2010_2025_v3.csv')

"""Performing Intial Checks"""

df.head(5)

df.tail(5)

print(df.shape)

print(df.columns)

df.info()

df.describe()

df.describe(include=["object", "bool"])

"""Handle missing values and duplicates"""

df.duplicated().sum()

df.isnull().sum()

"""Converting categorical features into numerical form"""

df.head(5)

df=pd.read_csv('/content/CLOUDPAK25_2010_2025_v3.csv')
from sklearn.preprocessing import LabelEncoder
encoder=LabelEncoder()
df['province_encoded'] = encoder.fit_transform(df['province'])
df['district_encoded'] = encoder.fit_transform(df['district'])

print(df.head())

"""**2 Exploratory Data Analysis (EDA)**

"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""Use NumPy & Pandas for basic statistics"""

df.describe()

"""Visualizing Data"""

df=pd.read_csv('/content/CLOUDPAK25_2010_2025_v3.csv')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

plt.hist(df['peak_rainfall_mm_per_hr'],bins=10,color='green',alpha=0.4)
plt.title('histrogram of peak rainfall')
plt.xlabel('peak rainfall')
plt.ylabel('frequency')
plt.show()

sns.boxplot(data=df[['latitude','longitude','area_km2']])
plt.show()

plt.figure(figsize=(8,6))
sns.scatterplot(data=df,x='duration_min',y='peak_rainfall_mm_per_hr',hue='district',palette='viridis')
plt.show()

import plotly.express as px

df=pd.read_csv('/content/CLOUDPAK25_2010_2025_v3.csv')

fig=px.scatter(df,x='peak_rainfall_mm_per_hr',y='duration_min',color='province')
fig.show()

"""**3. Feature Engineering**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

df=pd.read_csv('/content/CLOUDPAK25_2010_2025_v3.csv')

df.head(5)

from sklearn.preprocessing import LabelEncoder
encoder=LabelEncoder()
df['province_encoded'] = encoder.fit_transform(df['province'])
df['district_encoded'] = encoder.fit_transform(df['district'])

X = df[['province_encoded', 'district_encoded', 'latitude', 'longitude',
        'peak_rainfall_mm_per_hr', 'duration_min', 'area_km2']].values
y = df[['deaths']].values

from sklearn.preprocessing import MinMaxScaler

mscaler = MinMaxScaler()
df[['province_scaled', 'district_scaled']] = mscaler.fit_transform(df[['province_encoded', 'district_encoded']])

from sklearn.model_selection import train_test_split

mscaler = MinMaxScaler()
X_scaled = mscaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

print("Training features shape:", X_train.shape)
print("Training target shape:", y_train.shape)

df.describe()

df.head(5)

"""**4. Model Training**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

df=pd.read_csv('/content/CLOUDPAK25_2010_2025_v3.csv')

X = df.drop("deaths", axis=1)
y = df["deaths"]

# KNN Classifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)

# Decision Tree
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)
dt_pred = dt.predict(X_test)

# Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)

print("KNN Classifier Accuracy:", accuracy_score(y_test, knn_pred))
print("Decision Tree Accuracy:", accuracy_score(y_test, dt_pred))
print("Random Forest Accuracy:", accuracy_score(y_test, rf_pred))

print("\n classification report ")
print(classification_report(y_test, rf_pred))

print("\nConfusion Matrix (Random Forest):")
print(confusion_matrix(y_test, rf_pred))

"""**5. Feature Importance**"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)


importances = rf.feature_importances_
features = ['province_encoded', 'district_encoded', 'latitude', 'longitude',
            'peak_rainfall_mm_per_hr', 'duration_min', 'area_km2']

feat_importance_df = pd.DataFrame({
    "Feature": features,
    "Importance": importances
}).sort_values(by="Importance", ascending=False)

print(feat_importance_df)

plt.figure(figsize=(8,5))
plt.barh(feat_importance_df["Feature"], feat_importance_df["Importance"])
plt.gca().invert_yaxis()
plt.title("Feature Importance from Random Forest")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.show()

"""The model relies most heavily on peak rainfall (mm/hr), making it the strongest predictor. Location factors (latitude and longitude) also play a big role, followed by area size. Administrative encodings (district, province) and event duration matter less but still contribute.

Recommendation: Focus on peak rainfall and location variables when interpreting predictions.
Next step: Consider testing models with only the top features to see if performance remains strong.

**6. Hyperparameter Tuning**
"""

from sklearn.model_selection import RandomizedSearchCV
import numpy as np

# KNN hyperparameters
knn_params = {
    'n_neighbors': np.arange(1, 31),
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

# Decision Tree hyperparameters
dt_params = {
    'max_depth': np.arange(1, 21),
    'min_samples_split': np.arange(2, 11)
}

# Random Forest hyperparameters
rf_params = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [None, 5, 10, 20],
    'min_samples_split': [2, 5, 10]
}

# 1. KNN
knn_random = RandomizedSearchCV(
    estimator=KNeighborsClassifier(),
    param_distributions=knn_params,
    n_iter=20,
    cv=5,
    scoring='accuracy',
    random_state=42,
    n_jobs=-1
)
knn_random.fit(X_train, y_train)
print("Best KNN Params:", knn_random.best_params_)
print("Best KNN Accuracy:", knn_random.best_score_)

# 2. Decision Tree
dt_random = RandomizedSearchCV(
    estimator=DecisionTreeClassifier(random_state=42),
    param_distributions=dt_params,
    n_iter=20,
    cv=5,
    scoring='accuracy',
    random_state=42,
    n_jobs=-1
)
dt_random.fit(X_train, y_train)
print("Best Decision Tree Params:", dt_random.best_params_)
print("Best Decision Tree Accuracy:", dt_random.best_score_)

# 3. Random Forest
rf_random = RandomizedSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_distributions=rf_params,
    n_iter=20,
    cv=5,
    scoring='accuracy',
    random_state=42,
    n_jobs=-1
)
rf_random.fit(X_train, y_train)
print("Best Random Forest Params:", rf_random.best_params_)
print("Best Random Forest Accuracy:", rf_random.best_score_)

"""After tuning the hyperparameters, all three models showed an improvement compared to their default settings. For instance, the Random Forest performed the best overall, and by increasing the number of trees (n_estimators) and setting an optimal max_depth, its accuracy improved by around 3%. KNN also benefited from adjusting the number of neighbors and distance metric, while the Decision Tree performed better when we limited its depth to avoid overfitting. This shows that tuning is an essential step to get the most out of machine learning models.

**7. Model Evaluation**
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

models = {
    "KNN": (y_test, knn_pred),
    "Decision Tree": (y_test, dt_pred),
    "Random Forest": (y_test, rf_pred)
}

for name, (y_true, y_pred) in models.items():
    print(f"\n{name} Evaluation")
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred, average="weighted"))
    print("Recall:", recall_score(y_true, y_pred, average="weighted"))
    print("F1-score:", f1_score(y_true, y_pred, average="weighted"))
    print("\nClassification Report:\n", classification_report(y_true, y_pred))


    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(4,3))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

# Convert 'deaths' to a binary target (0: no deaths, 1: one or more deaths)
y_test_binary = (y_test > 0).astype(int)
# Get probability scores for the positive class (class 1)
y_proba = rf.predict_proba(X_test)[:, 1]

fpr, tpr, thresholds = roc_curve(y_test_binary, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, color="blue", label=f"ROC Curve (AUC = {roc_auc:.2f})")
plt.plot([0,1],[0,1], color="red", linestyle="--")  # baseline
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Random Forest (Binary Deaths)")
plt.legend(loc="lower right")
plt.show()

"""The Decision Tree model gave us an accuracy of 50%, which means it was correct only half of the time. While the precision score (≈0.55) was slightly better, the recall (0.50) shows that the model was still missing quite a lot of true cases. The F1-score (≈0.48), which balances precision and recall, also confirms that the model’s overall performance was weak.

In simple words: the Decision Tree struggled to make reliable predictions. It may have overfitted to the training data (learning too many specific rules) or underfitted (not learning enough patterns), which explains why its performance is not strong on the test data.

**8. Conclusion**

1. Which model performed best and why?
Among the three models tested, the Random Forest Classifier performed best with an accuracy of 70%, compared to 56% for KNN and 50% for Decision Tree. Random Forest worked better because it is an ensemble method that combines multiple decision trees, which reduces overfitting and captures more complex weather patterns. KNN struggled because the dataset likely contains overlapping classes, making distance-based classification less effective. The Decision Tree underperformed because it overfitted the training data and failed to generalize well on unseen test data.

2. Which features were most important?
From the Random Forest’s feature importance analysis, the most influential features were peak rainfall (mm/hr) and duration (minutes), since both directly describe the intensity and length of the rainfall event, which are the main drivers of cloud burst formation. Area (km²) also contributed notably, as larger affected areas may indicate stronger events. On the other hand, latitude and longitude were less important because while they locate the event geographically, they don’t directly determine whether a cloud burst occurs.

3. How did hyperparameter tuning improve results?
Hyperparameter tuning helped all models perform better than their default versions:

KNN: Selecting the right number of neighbors improved recall slightly, making the model less biased.

Decision Tree: Limiting depth and adjusting splits reduced overfitting, but overall performance still remained weak.

Random Forest: Tuning the number of trees and split criteria gave the biggest performance boost, leading to the highest accuracy and more balanced precision-recall trade-off.
"""